{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Pytorch Implementation of SinGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import io, transforms\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int,\n",
    "                 stride: int,\n",
    "                 padding: int) -> None:\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2, True)\n",
    "    \n",
    "    def forward(self,\n",
    "                x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.relu(self.norm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 3,\n",
    "                 out_channels: int = 32,\n",
    "                 kernel_size: int = 3,\n",
    "                 padding: int = 1,\n",
    "                 num_layers: int = 3) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.head = ConvBlock(in_channels, out_channels, kernel_size, 1, padding)\n",
    "        self.body = nn.Sequential(\n",
    "            ConvBlock(out_channels, out_channels, kernel_size, 1, padding)\n",
    "            for _ in range(num_layers)\n",
    "        )\n",
    "        self.tail = ConvBlock(out_channels, 1, kernel_size, 1, padding)\n",
    "        self.pad = nn.ZeroPad2d(5)\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pad(x)\n",
    "        x = self.head(x)\n",
    "        x = self.body(x)\n",
    "        return self.tail(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 3,\n",
    "                 out_channels: int = 32,\n",
    "                 kernel_size: int = 3,\n",
    "                 padding: int = 1,\n",
    "                 num_layers: int = 3) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.head = ConvBlock(in_channels, out_channels, kernel_size, 1, padding)\n",
    "        self.body = nn.Sequential(\n",
    "            ConvBlock(out_channels, out_channels, kernel_size, 1, padding)\n",
    "            for _ in range(num_layers)\n",
    "        )\n",
    "        self.tail = nn.Sequential(\n",
    "            ConvBlock(out_channels, in_channels, kernel_size, 1, padding),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.pad = nn.ZeroPad2d(5)\n",
    "    \n",
    "    def forward(self,\n",
    "                x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pad(x)\n",
    "        return x + self.tail(self.body(self.head(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(3, 4, 5)\n",
    "b.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 33, 44, 59, 79, 105, 140, 187, 250]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size_min, img_size_max = 25, 250\n",
    "scale_factor = 4 / 3\n",
    "number_of_scales = int(math.log(img_size_max / img_size_min, scale_factor)) # 8\n",
    "size_list = [round(img_size_min * pow(scale_factor, i)) for i in range(number_of_scales + 1)]\n",
    "size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 32, 32, 32, 64, 64, 64, 64, 128]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[32 * pow(2, i // 4) for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_features = 32\n",
    "generators = [Generator(out_channels=n_features * pow(2, i // 4)).to(device) for i in range(number_of_scales + 1)]\n",
    "discriminators = [Discriminator(out_channels=n_features * pow(2, i // 4)).to(device) for i in range(number_of_scales + 1)]\n",
    "lr = 5e-4\n",
    "beta1 = 0.5\n",
    "gamma = 0\n",
    "max_epochs = 2000\n",
    "d_iter = g_iter = 3\n",
    "alpha = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "img = io.read_image(path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update stage by stage\n",
    "for stage, (generator, discriminator, size) in enumerate(zip(generators, discriminators, size_list)):\n",
    "    optim_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    optim_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    scheduler_g = torch.optim.lr_scheduler.MultiStepLR(optim_g, milestones=[1600], gamma=gamma)\n",
    "    scheduler_d = torch.optim.lr_scheduler.MultiStepLR(optim_d, milestones=[1600], gamma=gamma)\n",
    "    \n",
    "    image = F.interpolate(img, size, mode='bilinear', align_corners=True)\n",
    "    x = torch.randn(*image.shape, device=device) if stage == 0 else None\n",
    "    for epoch in max_epochs:\n",
    "        # update Discriminator\n",
    "        for _ in range(d_iter):\n",
    "            y = discriminator()\n",
    "        \n",
    "        # update Generator\n",
    "        for _ in range(g_iter):\n",
    "            fake = generator(x)\n",
    "            loss = F.mse_loss(image, fake)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"3\".isdigit() << 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
